# -*- coding: utf-8 -*-
"""Topsis_Pretrained.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ukwtLZM5RFxAmDMvemw7HlLeCvoj2Kcb
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import time
from transformers import pipeline
from sklearn.metrics import accuracy_score, f1_score

# Define models to evaluate
models = [
    "distilbert-base-uncased-finetuned-sst-2-english",
    "roberta-base",
    "bert-base-uncased"
]

# Sample dataset (IMDb reviews)
data = [
    ("The movie was fantastic! I loved it.", 1),
    ("Absolutely terrible. Waste of time.", 0),
    ("Not bad, but could be better.", 1),
    ("One of the worst films I've ever seen.", 0),
    ("A masterpiece of cinema.", 1)
]

texts, labels = zip(*data)

# Evaluate models
results = []
for model in models:
    classifier = pipeline("text-classification", model=model)
    start_time = time.time()

    preds = []
    for text in texts:
        output = classifier(text)[0]
        predicted_label = 1 if output['label'] in ['POSITIVE', 'LABEL_1'] else 0  # Handling different label formats
        preds.append(predicted_label)

    end_time = time.time()

    accuracy = accuracy_score(labels, preds)
    f1 = f1_score(labels, preds)
    inference_time = (end_time - start_time) / len(texts)

    results.append([accuracy, f1, inference_time])

# Convert results to DataFrame
df = pd.DataFrame(results, columns=["Accuracy", "F1-score", "Inference Time"], index=models)

# Normalize data for TOPSIS
norm_df = df / np.sqrt((df**2).sum())

# Define weights and criteria (Higher is better for Accuracy & F1, Lower is better for Time)
weights = np.array([0.4, 0.4, 0.2])
criteria = np.array([1, 1, -1])

# Calculate ideal best and worst solutions
ideal_best = (criteria * norm_df).max()
ideal_worst = (criteria * norm_df).min()

# Compute distances
distance_best = np.sqrt(((norm_df - ideal_best) ** 2).sum(axis=1))
distance_worst = np.sqrt(((norm_df - ideal_worst) ** 2).sum(axis=1))

# Compute TOPSIS score
scores = distance_worst / (distance_best + distance_worst)
df["TOPSIS Score"] = scores

# Sort models based on TOPSIS ranking
df_sorted = df.sort_values(by="TOPSIS Score", ascending=False)

# Save results to CSV
df_sorted.to_csv("topsis_results.csv")

# Plot results
plt.figure(figsize=(8, 5))
sns.barplot(x=df_sorted.index, y=df_sorted["TOPSIS Score"], palette="viridis")

plt.xlabel("Model", fontsize=12)
plt.ylabel("TOPSIS Score", fontsize=12)
plt.title("TOPSIS Ranking of Pre-trained Models for Text Classification", fontsize=14)
plt.xticks(rotation=45)
plt.grid(axis="y", linestyle="--", alpha=0.7)

# Save plot as an image
plt.savefig("topsis_ranking.png")
plt.show()

# Print final results with explanation
print("\nModel Performance Analysis:")
print(df_sorted)
print("\nAnalysis:")
best_model = df_sorted.index[0]
print(f"The best model according to the TOPSIS ranking is **{best_model}**.")
print("A higher accuracy and F1-score indicate better predictive performance, while a lower inference time is preferable for real-time applications.")